---
title: "DMAOG performance evaluation"
author: "Herminio García-González"
date: "2023-08-28"
output: 
  html_document: default
  md_document:
    variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(summarytools)
library(FSA)
```

## Loading the dataset

Firstly we have to load the dataset from Github from the available project repository:

```{r}
dataset <- read.csv("https://raw.githubusercontent.com/herminiogg/dmaog-paper-evaluation/master/StatisticalAnalysis/dmaogEvaluationDataset.csv")[, 2:4]
```

## Descriptive statistics

We obtain the descriptive statistics for each of the tools that we have tested. We include in this analysis the mean, the standard deviation the minimum and the maximum:

```{r}
stby(dataset, dataset$Software, descr, round.digits=5, stats=c("mean", "sd", "min", "max"))
```

## Testing normality

In order to see if we can apply a One-Way ANOVA over the results we must ensure firstly that each of the data series are following a normal distribution. For this we will test again for each of the series that is combination of the tool and the tested method. 

Results for "All items" methods:

```{r}
by(dataset$All_items, dataset$Software, shapiro.test)
```

Results for "Search by fields" methods:
```{r}
by(dataset$Search_by_fields, dataset$Software, shapiro.test)
```

Looking to the results we can see that the the null hypothesis (the sample is following a normal distribution) is rejected in most of the cases, meaning that they those samples are not following a normal distribution and thereby we cannot apply a One-Way ANOVA to them as this is one of the assumptions of this test.

## Testing for differences of means
After the obtained results on normality distribution we can opt for a non-parametric test for difference of means. In this case we will use the Kruskal-Wallis test in which the null hypothesis assumes that the distributions have no differences.

Results for "All items" method:

```{r}
kruskal.test(All_items ~ Software, data = dataset)
```

Results for "Search by fields" method:

```{r}
kruskal.test(Search_by_fields ~ Software, data = dataset)
```

In the light of these results we can see that in both cases the null hypothesis is rejected and the significance of this difference can be classified as statistically highly significant with the significance level  p < 0.001.

In addition, we can measure the strength of this difference by measuring the effect size:

TODO

## Testing differences between groups
The Kruskal-Wallis tests tells us that there are differences between the four given distributions, however with it we cannot exactly know between which groups are those differences. For this purpouse we need to run a post hoc analysis. In this case we will use the Dunn's Test using the Benjamini-Hochberg procedure. 

Results for "All items" method:



```{r}
dunnTest(All_items ~ Software, data = dataset, method = "bh")
```

In the case of the "All items" method we can see that there are very significant differences (p < 0.001) between DMAOG and LDflex, between DMAOG and RDF4J-Beans, between LDflex and RDF4J-Beans, and between LDflex and Walder. Also there are significant differences (p < 0.05) between RDF4J-Beans and Walder and between DMAOG and Walder. In addition we can calculate the effect size to see how strong is the seen relation:

```{r, echo=FALSE}
library(rstatix)
```

```{r}
d_all_items <- dunn_test(All_items ~ Software, data = dataset, p.adjust.method = "BH")
d_all_items$r <- d_all_items$statistic / sqrt(d_all_items$n1+d_all_items$n2)
d_all_items[, c(1,2,3,10)]
```

As we can see from the previous results the effect size is large as per Cohen suggested values of effect size for r. Therefore, we can ensure that DMAOG is faster than LDflex, and RDF4J-Beans, and Walder is faster than LDflex. However, while we can ensure that DMAOG is faster than Walder, Walder is faster than RDF4J-Beans and RDF4J-Beans is faster than LDflex these relations have a medium effect size so the difference is less strong than in the other cases.

Results for "Search by fields" method:

```{r}
dunnTest(Search_by_fields ~ Software, data = dataset, method = "bh")
```

In this case there are very significant differences between DMAOG and RDF4J-Beans, RDF4J-Beans and Walder, between LDflex and Walder, and between DMAOG and LDflex. There are significant differences between LDflex and RDF4J-Beans and between DMAOG and Walder. Calculating the effect size:

```{r}
d_search_by_fields <- dunn_test(Search_by_fields ~ Software, data = dataset, p.adjust.method = "BH")
d_search_by_fields$r <- d_search_by_fields$statistic / sqrt(d_search_by_fields$n1+d_search_by_fields$n2)
d_search_by_fields[, c(1,2,3,10)]
```

We can see that pairing the previously obtained significance values there are large effect sizes between DMAOG and RDF4J-Beans (DMAOG is faster), between RDF4J-Beans and Walder (Walder is faster) and between LDflex and Walder (Walder is faster). We see medium size effects between DMAOG and LDflex (being DMAOG faster) between LDflex and RDF4J-Beans (being LDflex faster), and between DMAOG and Walder (being in this case Walder faster).

So we can corroborate that the previously observed differences and performance classification are statistically valid, so we can classify their performance depending on the used method:

All items: DMAOG, Walder, RDF4J-Beans, LDflex
Search by fields: Walder, DMAOG, LDflex and RDF4J-Beans

# Visualising the differences

We then can visualise these differences in a box plot where the differences can be become more evident. For that we are going to analyse the tools that interchange their position in best performance between the two tested methods:

RDF4J-Beans and LDflex:
```{r}
boxplot(
  filter(dataset, Software == "RDF4J-Beans")$All_items, 
  filter(dataset, Software == "LDflex")$All_items, 
  names=c("RDF4J-Beans - All items", "LDflex - All items"),
  notch=TRUE,
  col=c("yellow", "orange"))
```

```{r}
boxplot(
  filter(dataset, Software == "RDF4J-Beans")$Search_by_fields, 
  filter(dataset, Software == "LDflex")$Search_by_fields,
  names=c("RDF4J-Beans - Search by field", "LDflex - Search by field"),
  notch=TRUE,
  col=c("yellow", "orange"))
```


DMAOG and Walder:
```{r}
boxplot(
  filter(dataset, Software == "DMAOG")$All_items, 
  filter(dataset, Software == "Walder")$All_items, 
  names=c("DMAOG - All items", "Walder - All items"),
  notch=TRUE,
  col=c("red", "purple"))
```

```{r}
boxplot(
  filter(dataset, Software == "DMAOG")$Search_by_fields, 
  filter(dataset, Software == "Walder")$Search_by_fields,
  names=c("DMAOG - Search by field", "Walder - Search by field"),
  notch=TRUE,
  col=c("red", "purple"))
```


